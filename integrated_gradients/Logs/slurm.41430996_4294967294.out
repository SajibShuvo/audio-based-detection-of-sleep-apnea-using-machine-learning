All logs will be stored in ./Logs
Job started on sg231 at Wed Dec  3 22:01:18 MST 2025
SLURM_JOB_ID: 41430996
[INFO] Using device: cuda
[INFO] Total mel files found: 71
[INFO] Usable (mel, label) pairs: 71
[INFO] Patient-level split (files):
       Train: 49
       Val:   14
       Test:  8

[INFO] Building TRAIN dataset (female)...
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001258-100507.npy: 1809 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001202-100507.npy: 1315 segments, shape=(3, 64, 3001)
[WARN] Length mismatch for /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001556-100507.npy vs /scratch/sshuvo13/project_shared_folder_bspml_1/rml_analysis/fixed_rml_analysis/labels_again/fixed_30s_label_outputs/00001556-100507_segments_labels.npy: mel=2443, label=2803. Using first 2443 segments.
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001556-100507.npy: 2443 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001247-100507.npy: 1462 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001419-100507.npy: 1891 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001097-100507.npy: 1922 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001358-100507.npy: 1992 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001459-100507.npy: 1985 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001073-100507.npy: 1455 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001516-100507.npy: 2104 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001486-100507.npy: 1993 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001683-100507.npy: 2082 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001186-100507.npy: 1442 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001222-100507.npy: 1943 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001191-100507.npy: 1190 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001478-100507.npy: 1259 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001388-100507.npy: 1589 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001474-100507.npy: 1921 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001615-100507.npy: 2620 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001510-100507.npy: 1107 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001306-100507.npy: 1845 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001442-100507.npy: 1575 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001500-100507.npy: 2240 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001250-100507.npy: 2627 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001550-100507.npy: 1390 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001118-100507.npy: 1354 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001206-100507.npy: 1758 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001287-100507.npy: 2941 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001414-100507.npy: 1393 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001626-100507.npy: 2435 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001689-100507.npy: 2065 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001254-100507.npy: 1694 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001607-100507.npy: 2600 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001093-100507.npy: 1612 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001554-100507.npy: 2123 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001577-100507.npy: 2556 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001126-100507.npy: 1553 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001432-100507.npy: 1602 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001234-100507.npy: 1468 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001619-100507.npy: 2656 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001153-100507.npy: 1631 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00000995-100507.npy: 1788 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001643-100507.npy: 1992 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001623-100507.npy: 2458 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001679-100507.npy: 1973 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001568-100507.npy: 2118 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001263-100507.npy: 1902 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001367-100507.npy: 1516 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001451-100507.npy: 1813 segments, shape=(3, 64, 3001)
[INFO] Total female segments: 92202
[INFO] Found label classes: ['CentralApnea', 'CentralApnea;Hypopnea', 'CentralApnea;MixedApnea', 'CentralApnea;ObstructiveApnea', 'Hypopnea', 'Hypopnea;CentralApnea', 'Hypopnea;CentralApnea;ObstructiveApnea', 'Hypopnea;MixedApnea', 'Hypopnea;ObstructiveApnea', 'MixedApnea', 'MixedApnea;CentralApnea', 'MixedApnea;Hypopnea', 'MixedApnea;ObstructiveApnea', 'MixedApnea;ObstructiveApnea;Hypopnea', 'Normal', 'ObstructiveApnea', 'ObstructiveApnea;CentralApnea', 'ObstructiveApnea;CentralApnea;MixedApnea', 'ObstructiveApnea;Hypopnea', 'ObstructiveApnea;MixedApnea']
[INFO] Binary label mapping:
       Normal -> 0
       CentralApnea -> 1 (event)
       CentralApnea;Hypopnea -> 1 (event)
       CentralApnea;MixedApnea -> 1 (event)
       CentralApnea;ObstructiveApnea -> 1 (event)
       Hypopnea -> 1 (event)
       Hypopnea;CentralApnea -> 1 (event)
       Hypopnea;CentralApnea;ObstructiveApnea -> 1 (event)
       Hypopnea;MixedApnea -> 1 (event)
       Hypopnea;ObstructiveApnea -> 1 (event)
       MixedApnea -> 1 (event)
       MixedApnea;CentralApnea -> 1 (event)
       MixedApnea;Hypopnea -> 1 (event)
       MixedApnea;ObstructiveApnea -> 1 (event)
       MixedApnea;ObstructiveApnea;Hypopnea -> 1 (event)
       ObstructiveApnea -> 1 (event)
       ObstructiveApnea;CentralApnea -> 1 (event)
       ObstructiveApnea;CentralApnea;MixedApnea -> 1 (event)
       ObstructiveApnea;Hypopnea -> 1 (event)
       ObstructiveApnea;MixedApnea -> 1 (event)

[INFO] Building VAL dataset (female)...
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001424-100507.npy: 1671 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001457-100507.npy: 1335 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001161-100507.npy: 1737 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001687-100507.npy: 2158 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001614-100507.npy: 2626 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001411-100507.npy: 2284 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001335-100507.npy: 2161 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001695-100507.npy: 1981 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001642-100507.npy: 1104 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001084-100507.npy: 2169 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001016-100507.npy: 2183 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001020-100507.npy: 1650 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001282-100507.npy: 1385 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001398-100507.npy: 1932 segments, shape=(3, 64, 3001)
[INFO] Total female segments: 26376
[INFO] Found label classes: ['CentralApnea', 'CentralApnea;Hypopnea', 'CentralApnea;MixedApnea', 'CentralApnea;ObstructiveApnea', 'Hypopnea', 'Hypopnea;CentralApnea', 'Hypopnea;MixedApnea', 'Hypopnea;ObstructiveApnea', 'MixedApnea', 'MixedApnea;CentralApnea', 'MixedApnea;Hypopnea', 'MixedApnea;ObstructiveApnea', 'Normal', 'ObstructiveApnea', 'ObstructiveApnea;CentralApnea', 'ObstructiveApnea;Hypopnea', 'ObstructiveApnea;MixedApnea']
[INFO] Binary label mapping:
       Normal -> 0
       CentralApnea -> 1 (event)
       CentralApnea;Hypopnea -> 1 (event)
       CentralApnea;MixedApnea -> 1 (event)
       CentralApnea;ObstructiveApnea -> 1 (event)
       Hypopnea -> 1 (event)
       Hypopnea;CentralApnea -> 1 (event)
       Hypopnea;MixedApnea -> 1 (event)
       Hypopnea;ObstructiveApnea -> 1 (event)
       MixedApnea -> 1 (event)
       MixedApnea;CentralApnea -> 1 (event)
       MixedApnea;Hypopnea -> 1 (event)
       MixedApnea;ObstructiveApnea -> 1 (event)
       ObstructiveApnea -> 1 (event)
       ObstructiveApnea;CentralApnea -> 1 (event)
       ObstructiveApnea;Hypopnea -> 1 (event)
       ObstructiveApnea;MixedApnea -> 1 (event)

[INFO] Building TEST dataset (female)...
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001157-100507.npy: 1272 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001163-100507.npy: 1572 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001198-100507.npy: 1599 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001285-100507.npy: 1502 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001320-100507.npy: 1922 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001380-100507.npy: 1577 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001069-100507.npy: 1513 segments, shape=(3, 64, 3001)
[INFO] Processed /scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/female/mel_spectrum/00001171-100507.npy: 1258 segments, shape=(3, 64, 3001)
[INFO] Total female segments: 12215
[INFO] Found label classes: ['CentralApnea', 'CentralApnea;Hypopnea', 'CentralApnea;MixedApnea', 'CentralApnea;ObstructiveApnea', 'Hypopnea', 'Hypopnea;CentralApnea', 'Hypopnea;MixedApnea', 'Hypopnea;ObstructiveApnea', 'MixedApnea', 'MixedApnea;CentralApnea', 'MixedApnea;Hypopnea', 'MixedApnea;ObstructiveApnea', 'Normal', 'ObstructiveApnea', 'ObstructiveApnea;CentralApnea', 'ObstructiveApnea;Hypopnea', 'ObstructiveApnea;MixedApnea']
[INFO] Binary label mapping:
       Normal -> 0
       CentralApnea -> 1 (event)
       CentralApnea;Hypopnea -> 1 (event)
       CentralApnea;MixedApnea -> 1 (event)
       CentralApnea;ObstructiveApnea -> 1 (event)
       Hypopnea -> 1 (event)
       Hypopnea;CentralApnea -> 1 (event)
       Hypopnea;MixedApnea -> 1 (event)
       Hypopnea;ObstructiveApnea -> 1 (event)
       MixedApnea -> 1 (event)
       MixedApnea;CentralApnea -> 1 (event)
       MixedApnea;Hypopnea -> 1 (event)
       MixedApnea;ObstructiveApnea -> 1 (event)
       ObstructiveApnea -> 1 (event)
       ObstructiveApnea;CentralApnea -> 1 (event)
       ObstructiveApnea;Hypopnea -> 1 (event)
       ObstructiveApnea;MixedApnea -> 1 (event)

[INFO] Train segments: 92202
[INFO] Val segments:   26376
[INFO] Test segments:  12215
[INFO] Train negatives (0): 46700
[INFO] Train positives (1): 45502
[INFO] pos_weight = 1.0263
[INFO] Sequence feature dimension: 192

[INFO] Model architecture (FEMALE):
TinyMelTransformer(
  (proj): Linear(in_features=192, out_features=64, bias=True)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=128, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=128, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=1, bias=True)
  )
)

=== Epoch 1/20 (FEMALE) ===
[Epoch 1] Batch 200/2882 - Loss: 0.5777
[Epoch 1] Batch 400/2882 - Loss: 0.4550
[Epoch 1] Batch 600/2882 - Loss: 0.5287
[Epoch 1] Batch 800/2882 - Loss: 0.6394
[Epoch 1] Batch 1000/2882 - Loss: 0.5450
[Epoch 1] Batch 1200/2882 - Loss: 0.5045
[Epoch 1] Batch 1400/2882 - Loss: 0.5115
[Epoch 1] Batch 1600/2882 - Loss: 0.5252
[Epoch 1] Batch 1800/2882 - Loss: 0.7361
[Epoch 1] Batch 2000/2882 - Loss: 0.4411
[Epoch 1] Batch 2200/2882 - Loss: 0.4647
[Epoch 1] Batch 2400/2882 - Loss: 0.3305
[Epoch 1] Batch 2600/2882 - Loss: 0.4502
[Epoch 1] Batch 2800/2882 - Loss: 0.6823
[Epoch 1] Batch 2882/2882 - Loss: 0.4887
[TRAIN] Loss: 0.5353
[VAL] Accuracy: 0.6687
[VAL] ROC-AUC: 0.7044
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7721    0.7184    0.7443     17702
         1.0     0.4967    0.5671    0.5296      8674

    accuracy                         0.6687     26376
   macro avg     0.6344    0.6428    0.6369     26376
weighted avg     0.6815    0.6687    0.6737     26376

[INFO] New best val AUC (female): 0.7044 at epoch 1
[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch1.png

=== Epoch 2/20 (FEMALE) ===
[Epoch 2] Batch 200/2882 - Loss: 0.4076
[Epoch 2] Batch 400/2882 - Loss: 0.5345
[Epoch 2] Batch 600/2882 - Loss: 0.5537
[Epoch 2] Batch 800/2882 - Loss: 0.6255
[Epoch 2] Batch 1000/2882 - Loss: 0.5564
[Epoch 2] Batch 1200/2882 - Loss: 0.3797
[Epoch 2] Batch 1400/2882 - Loss: 0.4265
[Epoch 2] Batch 1600/2882 - Loss: 0.5015
[Epoch 2] Batch 1800/2882 - Loss: 0.6481
[Epoch 2] Batch 2000/2882 - Loss: 0.6321
[Epoch 2] Batch 2200/2882 - Loss: 0.4594
[Epoch 2] Batch 2400/2882 - Loss: 0.3764
[Epoch 2] Batch 2600/2882 - Loss: 0.3420
[Epoch 2] Batch 2800/2882 - Loss: 0.9170
[Epoch 2] Batch 2882/2882 - Loss: 0.5422
[TRAIN] Loss: 0.4894
[VAL] Accuracy: 0.6338
[VAL] ROC-AUC: 0.7167
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8180    0.5844    0.6818     17702
         1.0     0.4642    0.7347    0.5689      8674

    accuracy                         0.6338     26376
   macro avg     0.6411    0.6596    0.6253     26376
weighted avg     0.7017    0.6338    0.6446     26376

[INFO] New best val AUC (female): 0.7167 at epoch 2
[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch2.png

=== Epoch 3/20 (FEMALE) ===
[Epoch 3] Batch 200/2882 - Loss: 0.5742
[Epoch 3] Batch 400/2882 - Loss: 0.3251
[Epoch 3] Batch 600/2882 - Loss: 0.4480
[Epoch 3] Batch 800/2882 - Loss: 0.6342
[Epoch 3] Batch 1000/2882 - Loss: 0.3719
[Epoch 3] Batch 1200/2882 - Loss: 0.4281
[Epoch 3] Batch 1400/2882 - Loss: 0.3220
[Epoch 3] Batch 1600/2882 - Loss: 0.6738
[Epoch 3] Batch 1800/2882 - Loss: 0.4936
[Epoch 3] Batch 2000/2882 - Loss: 0.4881
[Epoch 3] Batch 2200/2882 - Loss: 0.3356
[Epoch 3] Batch 2400/2882 - Loss: 0.4330
[Epoch 3] Batch 2600/2882 - Loss: 0.4123
[Epoch 3] Batch 2800/2882 - Loss: 0.3771
[Epoch 3] Batch 2882/2882 - Loss: 0.4261
[TRAIN] Loss: 0.4669
[VAL] Accuracy: 0.6904
[VAL] ROC-AUC: 0.7200
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7853    0.7414    0.7627     17702
         1.0     0.5263    0.5862    0.5546      8674

    accuracy                         0.6904     26376
   macro avg     0.6558    0.6638    0.6587     26376
weighted avg     0.7001    0.6904    0.6943     26376

[INFO] New best val AUC (female): 0.7200 at epoch 3
[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch3.png

=== Epoch 4/20 (FEMALE) ===
[Epoch 4] Batch 200/2882 - Loss: 0.4539
[Epoch 4] Batch 400/2882 - Loss: 0.4212
[Epoch 4] Batch 600/2882 - Loss: 0.3832
[Epoch 4] Batch 800/2882 - Loss: 0.4227
[Epoch 4] Batch 1000/2882 - Loss: 0.4960
[Epoch 4] Batch 1200/2882 - Loss: 0.3286
[Epoch 4] Batch 1400/2882 - Loss: 0.5761
[Epoch 4] Batch 1600/2882 - Loss: 0.6154
[Epoch 4] Batch 1800/2882 - Loss: 0.3730
[Epoch 4] Batch 2000/2882 - Loss: 0.5153
[Epoch 4] Batch 2200/2882 - Loss: 0.5322
[Epoch 4] Batch 2400/2882 - Loss: 0.3667
[Epoch 4] Batch 2600/2882 - Loss: 0.4220
[Epoch 4] Batch 2800/2882 - Loss: 0.3890
[Epoch 4] Batch 2882/2882 - Loss: 0.1468
[TRAIN] Loss: 0.4509
[VAL] Accuracy: 0.6690
[VAL] ROC-AUC: 0.7337
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8112    0.6605    0.7281     17702
         1.0     0.4976    0.6863    0.5769      8674

    accuracy                         0.6690     26376
   macro avg     0.6544    0.6734    0.6525     26376
weighted avg     0.7081    0.6690    0.6784     26376

[INFO] New best val AUC (female): 0.7337 at epoch 4
[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch4.png

=== Epoch 5/20 (FEMALE) ===
[Epoch 5] Batch 200/2882 - Loss: 0.3029
[Epoch 5] Batch 400/2882 - Loss: 0.4913
[Epoch 5] Batch 600/2882 - Loss: 0.5839
[Epoch 5] Batch 800/2882 - Loss: 0.4705
[Epoch 5] Batch 1000/2882 - Loss: 0.2818
[Epoch 5] Batch 1200/2882 - Loss: 0.4259
[Epoch 5] Batch 1400/2882 - Loss: 0.3487
[Epoch 5] Batch 1600/2882 - Loss: 0.3706
[Epoch 5] Batch 1800/2882 - Loss: 0.4621
[Epoch 5] Batch 2000/2882 - Loss: 0.6220
[Epoch 5] Batch 2200/2882 - Loss: 0.3412
[Epoch 5] Batch 2400/2882 - Loss: 0.4356
[Epoch 5] Batch 2600/2882 - Loss: 0.3611
[Epoch 5] Batch 2800/2882 - Loss: 0.3204
[Epoch 5] Batch 2882/2882 - Loss: 0.4210
[TRAIN] Loss: 0.4395
[VAL] Accuracy: 0.6566
[VAL] ROC-AUC: 0.6975
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7768    0.6853    0.7282     17702
         1.0     0.4822    0.5981    0.5339      8674

    accuracy                         0.6566     26376
   macro avg     0.6295    0.6417    0.6311     26376
weighted avg     0.6799    0.6566    0.6643     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch5.png

=== Epoch 6/20 (FEMALE) ===
[Epoch 6] Batch 200/2882 - Loss: 0.5746
[Epoch 6] Batch 400/2882 - Loss: 0.4193
[Epoch 6] Batch 600/2882 - Loss: 0.4324
[Epoch 6] Batch 800/2882 - Loss: 0.5055
[Epoch 6] Batch 1000/2882 - Loss: 0.6583
[Epoch 6] Batch 1200/2882 - Loss: 0.5673
[Epoch 6] Batch 1400/2882 - Loss: 0.5523
[Epoch 6] Batch 1600/2882 - Loss: 0.3020
[Epoch 6] Batch 1800/2882 - Loss: 0.3385
[Epoch 6] Batch 2000/2882 - Loss: 0.3508
[Epoch 6] Batch 2200/2882 - Loss: 0.4567
[Epoch 6] Batch 2400/2882 - Loss: 0.2329
[Epoch 6] Batch 2600/2882 - Loss: 0.4501
[Epoch 6] Batch 2800/2882 - Loss: 0.3585
[Epoch 6] Batch 2882/2882 - Loss: 0.1812
[TRAIN] Loss: 0.4300
[VAL] Accuracy: 0.6589
[VAL] ROC-AUC: 0.6714
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7594    0.7198    0.7391     17702
         1.0     0.4832    0.5346    0.5076      8674

    accuracy                         0.6589     26376
   macro avg     0.6213    0.6272    0.6233     26376
weighted avg     0.6686    0.6589    0.6629     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch6.png

=== Epoch 7/20 (FEMALE) ===
[Epoch 7] Batch 200/2882 - Loss: 0.3301
[Epoch 7] Batch 400/2882 - Loss: 0.3627
[Epoch 7] Batch 600/2882 - Loss: 0.2787
[Epoch 7] Batch 800/2882 - Loss: 0.2947
[Epoch 7] Batch 1000/2882 - Loss: 0.3181
[Epoch 7] Batch 1200/2882 - Loss: 0.3849
[Epoch 7] Batch 1400/2882 - Loss: 0.3034
[Epoch 7] Batch 1600/2882 - Loss: 0.4941
[Epoch 7] Batch 1800/2882 - Loss: 0.2718
[Epoch 7] Batch 2000/2882 - Loss: 0.2506
[Epoch 7] Batch 2200/2882 - Loss: 0.3707
[Epoch 7] Batch 2400/2882 - Loss: 0.3860
[Epoch 7] Batch 2600/2882 - Loss: 0.4440
[Epoch 7] Batch 2800/2882 - Loss: 0.3217
[Epoch 7] Batch 2882/2882 - Loss: 0.4900
[TRAIN] Loss: 0.4217
[VAL] Accuracy: 0.6440
[VAL] ROC-AUC: 0.7044
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7826    0.6502    0.7103     17702
         1.0     0.4693    0.6314    0.5384      8674

    accuracy                         0.6440     26376
   macro avg     0.6260    0.6408    0.6243     26376
weighted avg     0.6796    0.6440    0.6538     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch7.png

=== Epoch 8/20 (FEMALE) ===
[Epoch 8] Batch 200/2882 - Loss: 0.5252
[Epoch 8] Batch 400/2882 - Loss: 0.4242
[Epoch 8] Batch 600/2882 - Loss: 0.4583
[Epoch 8] Batch 800/2882 - Loss: 0.4117
[Epoch 8] Batch 1000/2882 - Loss: 0.2714
[Epoch 8] Batch 1200/2882 - Loss: 0.4767
[Epoch 8] Batch 1400/2882 - Loss: 0.4253
[Epoch 8] Batch 1600/2882 - Loss: 0.6202
[Epoch 8] Batch 1800/2882 - Loss: 0.3211
[Epoch 8] Batch 2000/2882 - Loss: 0.2804
[Epoch 8] Batch 2200/2882 - Loss: 0.3015
[Epoch 8] Batch 2400/2882 - Loss: 0.4638
[Epoch 8] Batch 2600/2882 - Loss: 0.5947
[Epoch 8] Batch 2800/2882 - Loss: 0.2902
[Epoch 8] Batch 2882/2882 - Loss: 0.2027
[TRAIN] Loss: 0.4145
[VAL] Accuracy: 0.6153
[VAL] ROC-AUC: 0.7098
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8183    0.5487    0.6569     17702
         1.0     0.4493    0.7513    0.5623      8674

    accuracy                         0.6153     26376
   macro avg     0.6338    0.6500    0.6096     26376
weighted avg     0.6969    0.6153    0.6258     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch8.png

=== Epoch 9/20 (FEMALE) ===
[Epoch 9] Batch 200/2882 - Loss: 0.3935
[Epoch 9] Batch 400/2882 - Loss: 0.5169
[Epoch 9] Batch 600/2882 - Loss: 0.4203
[Epoch 9] Batch 800/2882 - Loss: 0.5921
[Epoch 9] Batch 1000/2882 - Loss: 0.5039
[Epoch 9] Batch 1200/2882 - Loss: 0.3111
[Epoch 9] Batch 1400/2882 - Loss: 0.4089
[Epoch 9] Batch 1600/2882 - Loss: 0.2167
[Epoch 9] Batch 1800/2882 - Loss: 0.2908
[Epoch 9] Batch 2000/2882 - Loss: 0.4935
[Epoch 9] Batch 2200/2882 - Loss: 0.3215
[Epoch 9] Batch 2400/2882 - Loss: 0.4830
[Epoch 9] Batch 2600/2882 - Loss: 0.4360
[Epoch 9] Batch 2800/2882 - Loss: 0.5518
[Epoch 9] Batch 2882/2882 - Loss: 0.1290
[TRAIN] Loss: 0.4086
[VAL] Accuracy: 0.6513
[VAL] ROC-AUC: 0.7085
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7857    0.6605    0.7177     17702
         1.0     0.4772    0.6323    0.5439      8674

    accuracy                         0.6513     26376
   macro avg     0.6315    0.6464    0.6308     26376
weighted avg     0.6843    0.6513    0.6606     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch9.png

=== Epoch 10/20 (FEMALE) ===
[Epoch 10] Batch 200/2882 - Loss: 0.3502
[Epoch 10] Batch 400/2882 - Loss: 0.5997
[Epoch 10] Batch 600/2882 - Loss: 0.3365
[Epoch 10] Batch 800/2882 - Loss: 0.4403
[Epoch 10] Batch 1000/2882 - Loss: 0.5552
[Epoch 10] Batch 1200/2882 - Loss: 0.4327
[Epoch 10] Batch 1400/2882 - Loss: 0.4877
[Epoch 10] Batch 1600/2882 - Loss: 0.2800
[Epoch 10] Batch 1800/2882 - Loss: 0.6231
[Epoch 10] Batch 2000/2882 - Loss: 0.3223
[Epoch 10] Batch 2200/2882 - Loss: 0.4883
[Epoch 10] Batch 2400/2882 - Loss: 0.7160
[Epoch 10] Batch 2600/2882 - Loss: 0.4415
[Epoch 10] Batch 2800/2882 - Loss: 0.5436
[Epoch 10] Batch 2882/2882 - Loss: 0.4341
[TRAIN] Loss: 0.4036
[VAL] Accuracy: 0.6662
[VAL] ROC-AUC: 0.6936
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7588    0.7370    0.7477     17702
         1.0     0.4930    0.5219    0.5070      8674

    accuracy                         0.6662     26376
   macro avg     0.6259    0.6294    0.6274     26376
weighted avg     0.6714    0.6662    0.6686     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch10.png

=== Epoch 11/20 (FEMALE) ===
[Epoch 11] Batch 200/2882 - Loss: 0.4889
[Epoch 11] Batch 400/2882 - Loss: 0.2587
[Epoch 11] Batch 600/2882 - Loss: 0.3404
[Epoch 11] Batch 800/2882 - Loss: 0.3956
[Epoch 11] Batch 1000/2882 - Loss: 0.3104
[Epoch 11] Batch 1200/2882 - Loss: 0.4173
[Epoch 11] Batch 1400/2882 - Loss: 0.3998
[Epoch 11] Batch 1600/2882 - Loss: 0.2892
[Epoch 11] Batch 1800/2882 - Loss: 0.4690
[Epoch 11] Batch 2000/2882 - Loss: 0.5184
[Epoch 11] Batch 2200/2882 - Loss: 0.3373
[Epoch 11] Batch 2400/2882 - Loss: 0.3362
[Epoch 11] Batch 2600/2882 - Loss: 0.4053
[Epoch 11] Batch 2800/2882 - Loss: 0.2646
[Epoch 11] Batch 2882/2882 - Loss: 0.1496
[TRAIN] Loss: 0.3993
[VAL] Accuracy: 0.6443
[VAL] ROC-AUC: 0.7225
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8036    0.6219    0.7012     17702
         1.0     0.4720    0.6899    0.5605      8674

    accuracy                         0.6443     26376
   macro avg     0.6378    0.6559    0.6309     26376
weighted avg     0.6946    0.6443    0.6549     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch11.png

=== Epoch 12/20 (FEMALE) ===
[Epoch 12] Batch 200/2882 - Loss: 0.3890
[Epoch 12] Batch 400/2882 - Loss: 0.4357
[Epoch 12] Batch 600/2882 - Loss: 0.4261
[Epoch 12] Batch 800/2882 - Loss: 0.2993
[Epoch 12] Batch 1000/2882 - Loss: 0.3781
[Epoch 12] Batch 1200/2882 - Loss: 0.3095
[Epoch 12] Batch 1400/2882 - Loss: 0.4084
[Epoch 12] Batch 1600/2882 - Loss: 0.3703
[Epoch 12] Batch 1800/2882 - Loss: 0.3330
[Epoch 12] Batch 2000/2882 - Loss: 0.5162
[Epoch 12] Batch 2200/2882 - Loss: 0.3512
[Epoch 12] Batch 2400/2882 - Loss: 0.2999
[Epoch 12] Batch 2600/2882 - Loss: 0.3592
[Epoch 12] Batch 2800/2882 - Loss: 0.4007
[Epoch 12] Batch 2882/2882 - Loss: 0.3278
[TRAIN] Loss: 0.3925
[VAL] Accuracy: 0.6470
[VAL] ROC-AUC: 0.7180
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8081    0.6216    0.7027     17702
         1.0     0.4750    0.6988    0.5656      8674

    accuracy                         0.6470     26376
   macro avg     0.6415    0.6602    0.6341     26376
weighted avg     0.6986    0.6470    0.6576     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch12.png

=== Epoch 13/20 (FEMALE) ===
[Epoch 13] Batch 200/2882 - Loss: 0.3404
[Epoch 13] Batch 400/2882 - Loss: 0.3105
[Epoch 13] Batch 600/2882 - Loss: 0.2875
[Epoch 13] Batch 800/2882 - Loss: 0.2633
[Epoch 13] Batch 1000/2882 - Loss: 0.5621
[Epoch 13] Batch 1200/2882 - Loss: 0.2120
[Epoch 13] Batch 1400/2882 - Loss: 0.3732
[Epoch 13] Batch 1600/2882 - Loss: 0.6193
[Epoch 13] Batch 1800/2882 - Loss: 0.5190
[Epoch 13] Batch 2000/2882 - Loss: 0.4481
[Epoch 13] Batch 2200/2882 - Loss: 0.3844
[Epoch 13] Batch 2400/2882 - Loss: 0.2316
[Epoch 13] Batch 2600/2882 - Loss: 0.5266
[Epoch 13] Batch 2800/2882 - Loss: 0.3581
[Epoch 13] Batch 2882/2882 - Loss: 0.3269
[TRAIN] Loss: 0.3885
[VAL] Accuracy: 0.6518
[VAL] ROC-AUC: 0.7097
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7925    0.6519    0.7154     17702
         1.0     0.4785    0.6517    0.5518      8674

    accuracy                         0.6518     26376
   macro avg     0.6355    0.6518    0.6336     26376
weighted avg     0.6892    0.6518    0.6616     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch13.png

=== Epoch 14/20 (FEMALE) ===
[Epoch 14] Batch 200/2882 - Loss: 0.2963
[Epoch 14] Batch 400/2882 - Loss: 0.3673
[Epoch 14] Batch 600/2882 - Loss: 0.5614
[Epoch 14] Batch 800/2882 - Loss: 0.3493
[Epoch 14] Batch 1000/2882 - Loss: 0.3171
[Epoch 14] Batch 1200/2882 - Loss: 0.3502
[Epoch 14] Batch 1400/2882 - Loss: 0.4268
[Epoch 14] Batch 1600/2882 - Loss: 0.2496
[Epoch 14] Batch 1800/2882 - Loss: 0.4213
[Epoch 14] Batch 2000/2882 - Loss: 0.4045
[Epoch 14] Batch 2200/2882 - Loss: 0.2520
[Epoch 14] Batch 2400/2882 - Loss: 0.4211
[Epoch 14] Batch 2600/2882 - Loss: 0.4322
[Epoch 14] Batch 2800/2882 - Loss: 0.3179
[Epoch 14] Batch 2882/2882 - Loss: 0.3183
[TRAIN] Loss: 0.3854
[VAL] Accuracy: 0.6513
[VAL] ROC-AUC: 0.7236
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8138    0.6231    0.7058     17702
         1.0     0.4796    0.7090    0.5722      8674

    accuracy                         0.6513     26376
   macro avg     0.6467    0.6661    0.6390     26376
weighted avg     0.7039    0.6513    0.6619     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch14.png

=== Epoch 15/20 (FEMALE) ===
[Epoch 15] Batch 200/2882 - Loss: 0.3118
[Epoch 15] Batch 400/2882 - Loss: 0.4373
[Epoch 15] Batch 600/2882 - Loss: 0.4328
[Epoch 15] Batch 800/2882 - Loss: 0.3841
[Epoch 15] Batch 1000/2882 - Loss: 0.3920
[Epoch 15] Batch 1200/2882 - Loss: 0.3623
[Epoch 15] Batch 1400/2882 - Loss: 0.3858
[Epoch 15] Batch 1600/2882 - Loss: 0.3238
[Epoch 15] Batch 1800/2882 - Loss: 0.3614
[Epoch 15] Batch 2000/2882 - Loss: 0.3210
[Epoch 15] Batch 2200/2882 - Loss: 0.4493
[Epoch 15] Batch 2400/2882 - Loss: 0.4709
[Epoch 15] Batch 2600/2882 - Loss: 0.5137
[Epoch 15] Batch 2800/2882 - Loss: 0.4022
[Epoch 15] Batch 2882/2882 - Loss: 0.1613
[TRAIN] Loss: 0.3816
[VAL] Accuracy: 0.6490
[VAL] ROC-AUC: 0.7122
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7978    0.6390    0.7096     17702
         1.0     0.4761    0.6695    0.5565      8674

    accuracy                         0.6490     26376
   macro avg     0.6370    0.6542    0.6331     26376
weighted avg     0.6920    0.6490    0.6593     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch15.png

=== Epoch 16/20 (FEMALE) ===
[Epoch 16] Batch 200/2882 - Loss: 0.5613
[Epoch 16] Batch 400/2882 - Loss: 0.3777
[Epoch 16] Batch 600/2882 - Loss: 0.3416
[Epoch 16] Batch 800/2882 - Loss: 0.3006
[Epoch 16] Batch 1000/2882 - Loss: 0.3451
[Epoch 16] Batch 1200/2882 - Loss: 0.3651
[Epoch 16] Batch 1400/2882 - Loss: 0.5144
[Epoch 16] Batch 1600/2882 - Loss: 0.5373
[Epoch 16] Batch 1800/2882 - Loss: 0.2445
[Epoch 16] Batch 2000/2882 - Loss: 0.2921
[Epoch 16] Batch 2200/2882 - Loss: 0.3407
[Epoch 16] Batch 2400/2882 - Loss: 0.3362
[Epoch 16] Batch 2600/2882 - Loss: 0.5586
[Epoch 16] Batch 2800/2882 - Loss: 0.5068
[Epoch 16] Batch 2882/2882 - Loss: 0.1787
[TRAIN] Loss: 0.3775
[VAL] Accuracy: 0.6346
[VAL] ROC-AUC: 0.7162
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8120    0.5928    0.6853     17702
         1.0     0.4642    0.7200    0.5645      8674

    accuracy                         0.6346     26376
   macro avg     0.6381    0.6564    0.6249     26376
weighted avg     0.6977    0.6346    0.6456     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch16.png

=== Epoch 17/20 (FEMALE) ===
[Epoch 17] Batch 200/2882 - Loss: 0.3370
[Epoch 17] Batch 400/2882 - Loss: 0.4095
[Epoch 17] Batch 600/2882 - Loss: 0.2389
[Epoch 17] Batch 800/2882 - Loss: 0.3855
[Epoch 17] Batch 1000/2882 - Loss: 0.5496
[Epoch 17] Batch 1200/2882 - Loss: 0.5576
[Epoch 17] Batch 1400/2882 - Loss: 0.5853
[Epoch 17] Batch 1600/2882 - Loss: 0.3502
[Epoch 17] Batch 1800/2882 - Loss: 0.5495
[Epoch 17] Batch 2000/2882 - Loss: 0.2549
[Epoch 17] Batch 2200/2882 - Loss: 0.5014
[Epoch 17] Batch 2400/2882 - Loss: 0.3736
[Epoch 17] Batch 2600/2882 - Loss: 0.5985
[Epoch 17] Batch 2800/2882 - Loss: 0.3148
[Epoch 17] Batch 2882/2882 - Loss: 0.3852
[TRAIN] Loss: 0.3742
[VAL] Accuracy: 0.6729
[VAL] ROC-AUC: 0.7452
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8163    0.6616    0.7308     17702
         1.0     0.5020    0.6961    0.5833      8674

    accuracy                         0.6729     26376
   macro avg     0.6591    0.6788    0.6571     26376
weighted avg     0.7129    0.6729    0.6823     26376

[INFO] New best val AUC (female): 0.7452 at epoch 17
[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch17.png

=== Epoch 18/20 (FEMALE) ===
[Epoch 18] Batch 200/2882 - Loss: 0.3717
[Epoch 18] Batch 400/2882 - Loss: 0.3841
[Epoch 18] Batch 600/2882 - Loss: 0.3160
[Epoch 18] Batch 800/2882 - Loss: 0.4837
[Epoch 18] Batch 1000/2882 - Loss: 0.4375
[Epoch 18] Batch 1200/2882 - Loss: 0.2496
[Epoch 18] Batch 1400/2882 - Loss: 0.4413
[Epoch 18] Batch 1600/2882 - Loss: 0.3644
[Epoch 18] Batch 1800/2882 - Loss: 0.3741
[Epoch 18] Batch 2000/2882 - Loss: 0.3121
[Epoch 18] Batch 2200/2882 - Loss: 0.2447
[Epoch 18] Batch 2400/2882 - Loss: 0.2506
[Epoch 18] Batch 2600/2882 - Loss: 0.4834
[Epoch 18] Batch 2800/2882 - Loss: 0.2892
[Epoch 18] Batch 2882/2882 - Loss: 0.5728
[TRAIN] Loss: 0.3707
[VAL] Accuracy: 0.6417
[VAL] ROC-AUC: 0.7144
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8045    0.6157    0.6976     17702
         1.0     0.4697    0.6947    0.5605      8674

    accuracy                         0.6417     26376
   macro avg     0.6371    0.6552    0.6290     26376
weighted avg     0.6944    0.6417    0.6525     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch18.png

=== Epoch 19/20 (FEMALE) ===
[Epoch 19] Batch 200/2882 - Loss: 0.2760
[Epoch 19] Batch 400/2882 - Loss: 0.3920
[Epoch 19] Batch 600/2882 - Loss: 0.3673
[Epoch 19] Batch 800/2882 - Loss: 0.3558
[Epoch 19] Batch 1000/2882 - Loss: 0.3620
[Epoch 19] Batch 1200/2882 - Loss: 0.3509
[Epoch 19] Batch 1400/2882 - Loss: 0.3673
[Epoch 19] Batch 1600/2882 - Loss: 0.3333
[Epoch 19] Batch 1800/2882 - Loss: 0.3265
[Epoch 19] Batch 2000/2882 - Loss: 0.4849
[Epoch 19] Batch 2200/2882 - Loss: 0.2765
[Epoch 19] Batch 2400/2882 - Loss: 0.5119
[Epoch 19] Batch 2600/2882 - Loss: 0.6085
[Epoch 19] Batch 2800/2882 - Loss: 0.2427
[Epoch 19] Batch 2882/2882 - Loss: 0.2816
[TRAIN] Loss: 0.3689
[VAL] Accuracy: 0.6672
[VAL] ROC-AUC: 0.7052
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.7790    0.7037    0.7394     17702
         1.0     0.4949    0.5926    0.5394      8674

    accuracy                         0.6672     26376
   macro avg     0.6370    0.6481    0.6394     26376
weighted avg     0.6856    0.6672    0.6736     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch19.png

=== Epoch 20/20 (FEMALE) ===
[Epoch 20] Batch 200/2882 - Loss: 0.3472
[Epoch 20] Batch 400/2882 - Loss: 0.3375
[Epoch 20] Batch 600/2882 - Loss: 0.2879
[Epoch 20] Batch 800/2882 - Loss: 0.2433
[Epoch 20] Batch 1000/2882 - Loss: 0.4060
[Epoch 20] Batch 1200/2882 - Loss: 0.3509
[Epoch 20] Batch 1400/2882 - Loss: 0.4802
[Epoch 20] Batch 1600/2882 - Loss: 0.1957
[Epoch 20] Batch 1800/2882 - Loss: 0.4229
[Epoch 20] Batch 2000/2882 - Loss: 0.3203
[Epoch 20] Batch 2200/2882 - Loss: 0.2971
[Epoch 20] Batch 2400/2882 - Loss: 0.3805
[Epoch 20] Batch 2600/2882 - Loss: 0.4086
[Epoch 20] Batch 2800/2882 - Loss: 0.5544
[Epoch 20] Batch 2882/2882 - Loss: 0.3280
[TRAIN] Loss: 0.3659
[VAL] Accuracy: 0.6240
[VAL] ROC-AUC: 0.7064
[VAL] Classification report:
              precision    recall  f1-score   support

         0.0     0.8030    0.5827    0.6754     17702
         1.0     0.4541    0.7083    0.5534      8674

    accuracy                         0.6240     26376
   macro avg     0.6286    0.6455    0.6144     26376
weighted avg     0.6883    0.6240    0.6352     26376

[INFO] Saved confusion matrix to confusion_matrix_val_female_transformer_epoch20.png

[INFO] Loaded best FEMALE model with val AUC = 0.7452

[INFO] Evaluating on TEST set (female)...
[TEST] Accuracy: 0.7216
[TEST] ROC-AUC: 0.7837
[TEST] Classification report:
              precision    recall  f1-score   support

         0.0     0.6687    0.7242    0.6953      5359
         1.0     0.7695    0.7195    0.7436      6856

    accuracy                         0.7216     12215
   macro avg     0.7191    0.7219    0.7195     12215
weighted avg     0.7252    0.7216    0.7225     12215

[INFO] Saved best model to /scratch/jbfrantz/jess_explainability_model/jess_outputs/best_female_transformer.pt
[INFO] Saved dataset metadata to /scratch/jbfrantz/jess_explainability_model/jess_outputs/dataset_metadata.npz
[INFO] Saved confusion matrix to confusion_matrix_test_female_transformer.png

[INFO] Done (female).
Job finished at Wed Dec  3 22:23:16 MST 2025
