{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65dc2bf-5e0b-4019-9bd2-8359dec4ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imblearn found: using RandomOverSampler inside CV pipelines.\n",
      "Loading data...\n",
      "Train shape: (103302, 34); Test shape: (27491, 34)\n",
      "Saved: model_outputs/metadata.json\n",
      "\n",
      "Tuning logreg ... (scoring=recall for Apnea)\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best logreg recall (CV): 0.6412\n",
      "Best params for logreg: {'clf__C': 10.0}\n",
      "Saved: model_outputs/logreg_best_params.json\n",
      "\n",
      "Tuning rf ... (scoring=recall for Apnea)\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best rf recall (CV): 0.8292\n",
      "Best params for rf: {'clf__n_estimators': 100, 'clf__max_depth': None}\n",
      "Saved: model_outputs/rf_best_params.json\n",
      "\n",
      "Tuning hgb ... (scoring=recall for Apnea)\n",
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "Best hgb recall (CV): 0.8074\n",
      "Best params for hgb: {'clf__max_iter': 200, 'clf__max_depth': 7, 'clf__learning_rate': 0.1}\n",
      "Saved: model_outputs/hgb_best_params.json\n",
      "Saved: model_outputs/cv_results_summary.json\n",
      "\n",
      "Refitting chosen estimators on full training data...\n",
      "Refitting logreg ...\n",
      "Refitting rf ...\n",
      "Refitting hgb ...\n",
      "Saved models.\n",
      "\n",
      "Evaluating on test set...\n",
      "Saved: model_outputs/test_metrics_default_threshold.json\n",
      "Default-threshold metrics saved.\n",
      "Saved: model_outputs/best_threshold_summary.json\n",
      "Selected best threshold by PR-F1: 0.3463 (F1=0.6203, P=0.4682, R=0.9187)\n",
      "Saved: model_outputs/test_metrics_best_threshold.json\n",
      "Best-threshold metrics saved.\n",
      "Saved: model_outputs/roc_curve_improved.png\n",
      "Saved: model_outputs/precision_recall_curve_improved.png\n",
      "Saved: model_outputs/confusion_matrix_improved.png\n",
      "Saved: model_outputs/calibration_curve_improved.png\n",
      "Saved: model_outputs/rf_feature_importances_improved.png\n",
      "Saved: model_outputs/feature_importances_improved.json\n",
      "Saved predictions to model_outputs/test_predictions_improved.csv\n",
      "Saved: model_outputs/final_summary_improved.json\n",
      "\n",
      "Done. All outputs are in: model_outputs\n"
     ]
    }
   ],
   "source": [
    "# Full corrected end-to-end pipeline (Jupyter cell)\n",
    "# - Apnea mapped to positive class (1)\n",
    "# - Imblearn RandomOverSampler used if installed, else manual upsample\n",
    "# - RandomizedSearchCV optimizing recall (3-fold)\n",
    "# - Efficient threshold selection using precision_recall_curve\n",
    "# - Saves plots (.png) and metrics (.json)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, classification_report, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.base import clone\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "# ---------------------------\n",
    "# User-editable paths & options\n",
    "# ---------------------------\n",
    "TRAIN_CSV = \"/scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/train_test_separated_and_combined/male/feature33/train_data.csv\"   # <- change to your training csv path\n",
    "TEST_CSV  = \"/scratch/sshuvo13/project_shared_folder_bspml_1/segments_30s/features/train_test_separated_and_combined/male/feature33/test_data.csv\"    # <- change to your test csv path\n",
    "\n",
    "OUT_DIR   = \"model_outputs\"\n",
    "N_JOBS    = -1\n",
    "RANDOM_STATE = 42\n",
    "FEATURE_COUNT = 33   # first 33 columns are features\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    path = Path(OUT_DIR) / name\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "def save_json(obj, name):\n",
    "    path = Path(OUT_DIR) / name\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2, default=lambda o: float(o) if isinstance(o, (np.floating, np.integer)) else str(o))\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Try imblearn\n",
    "# ---------------------------\n",
    "USE_IMBLEARN = True\n",
    "try:\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    print(\"imblearn found: using RandomOverSampler inside CV pipelines.\")\n",
    "except Exception:\n",
    "    print(\"imblearn not available - will fall back to manual upsampling.\")\n",
    "    USE_IMBLEARN = False\n",
    "\n",
    "# ---------------------------\n",
    "# Load data\n",
    "# ---------------------------\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv(TRAIN_CSV, low_memory=False)\n",
    "test  = pd.read_csv(TEST_CSV, low_memory=False)\n",
    "print(f\"Train shape: {train.shape}; Test shape: {test.shape}\")\n",
    "\n",
    "X_train = train.iloc[:, :FEATURE_COUNT].copy()\n",
    "y_train_raw = train.iloc[:, -1].astype(str).copy()\n",
    "X_test  = test.iloc[:, :FEATURE_COUNT].copy()\n",
    "y_test_raw = test.iloc[:, -1].astype(str).copy()\n",
    "\n",
    "# Cast numeric columns to float32 where possible to save memory\n",
    "for df in (X_train, X_test):\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# Map labels so Apnea=1, Normal=0\n",
    "# ---------------------------\n",
    "y_train = (y_train_raw == \"Apnea\").astype(int).values\n",
    "y_test  = (y_test_raw  == \"Apnea\").astype(int).values\n",
    "meta = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"train_shape\": train.shape,\n",
    "    \"test_shape\": test.shape,\n",
    "    \"feature_count\": FEATURE_COUNT,\n",
    "    \"label_map\": {\"Apnea\": 1, \"Normal\": 0},\n",
    "    \"train_pos_fraction\": float(y_train.mean()),\n",
    "    \"test_pos_fraction\": float(y_test.mean())\n",
    "}\n",
    "save_json(meta, \"metadata.json\")\n",
    "\n",
    "# ---------------------------\n",
    "# Manual safe upsampling fallback\n",
    "# ---------------------------\n",
    "def simple_upsample(X_df, y_arr, random_state=RANDOM_STATE):\n",
    "    df = pd.DataFrame(X_df.copy())\n",
    "    df['_y_'] = y_arr\n",
    "    counts = df['_y_'].value_counts()\n",
    "    if len(counts) == 1:\n",
    "        return X_df.values, y_arr\n",
    "    max_count = counts.max()\n",
    "    parts = []\n",
    "    for cls, cnt in counts.items():\n",
    "        sub = df[df['_y_'] == cls]\n",
    "        if cnt < max_count:\n",
    "            sub_up = sub.sample(n=max_count, replace=True, random_state=random_state)\n",
    "            parts.append(sub_up)\n",
    "        else:\n",
    "            parts.append(sub)\n",
    "    df_up = pd.concat(parts).sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "    y_up = df_up['_y_'].values.astype(int)\n",
    "    X_up = df_up.drop(columns=['_y_']).values.astype(np.float32)\n",
    "    return X_up, y_up\n",
    "\n",
    "# Prepare sampler or balanced data\n",
    "if USE_IMBLEARN:\n",
    "    sampler = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "else:\n",
    "    X_train_bal, y_train_bal = simple_upsample(X_train, y_train)\n",
    "    print(\"Manual upsampled training shape:\", X_train_bal.shape, y_train_bal.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# Build pipelines and small param grids\n",
    "# ---------------------------\n",
    "base_steps = [(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "\n",
    "# Logistic Regression (class_weight balanced)\n",
    "pipe_lr = Pipeline(base_steps + [(\"clf\", LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\", random_state=RANDOM_STATE, max_iter=200))])\n",
    "param_dist_lr = {\"clf__C\": [0.01, 0.1, 1.0, 10.0]}\n",
    "\n",
    "# Random Forest (class_weight balanced)\n",
    "pipe_rf = Pipeline(base_steps + [(\"clf\", RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\", n_jobs=1))])\n",
    "param_dist_rf = {\"clf__n_estimators\": [50, 100], \"clf__max_depth\": [5, 10, None]}\n",
    "\n",
    "# HistGradientBoosting (no class_weight param typically)\n",
    "pipe_hgb = Pipeline(base_steps + [(\"clf\", HistGradientBoostingClassifier(random_state=RANDOM_STATE))])\n",
    "param_dist_hgb = {\"clf__learning_rate\": [0.01, 0.1], \"clf__max_iter\": [100, 200], \"clf__max_depth\": [3, 7, None]}\n",
    "\n",
    "models = [\n",
    "    (\"logreg\", pipe_lr, param_dist_lr),\n",
    "    (\"rf\",     pipe_rf, param_dist_rf),\n",
    "    (\"hgb\",    pipe_hgb, param_dist_hgb),\n",
    "]\n",
    "\n",
    "# If using imblearn, create imblearn pipelines that include sampler\n",
    "if USE_IMBLEARN:\n",
    "    models_with_sampler = []\n",
    "    for name, pipe, params in models:\n",
    "        imb_pipe = ImbPipeline([(\"sampler\", sampler)] + pipe.steps)\n",
    "        models_with_sampler.append((name, imb_pipe, params))\n",
    "    models = models_with_sampler\n",
    "\n",
    "# ---------------------------\n",
    "# RandomizedSearchCV (3-fold) optimizing recall (Apnea)\n",
    "# ---------------------------\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "best_estimators = {}\n",
    "cv_results_summary = {}\n",
    "\n",
    "for name, pipe, param_dist in models:\n",
    "    print(f\"\\nTuning {name} ... (scoring=recall for Apnea)\")\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=min(8, max(3, sum(len(v) for v in param_dist.values()))),\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=cv,\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    if USE_IMBLEARN:\n",
    "        rs.fit(X_train, y_train)\n",
    "    else:\n",
    "        rs.fit(X_train_bal, y_train_bal)\n",
    "    print(f\"Best {name} recall (CV): {rs.best_score_:.4f}\")\n",
    "    print(f\"Best params for {name}: {rs.best_params_}\")\n",
    "    best_estimators[name] = rs.best_estimator_\n",
    "    # save compact cv results\n",
    "    cv_res = rs.cv_results_.copy()\n",
    "    def tidy(v):\n",
    "        if isinstance(v, np.ndarray): return v.tolist()\n",
    "        if isinstance(v, (np.float32, np.float64, np.int32, np.int64)): return float(v)\n",
    "        return v\n",
    "    cv_results_summary[name] = {k: tidy(v) for k, v in cv_res.items() if k in [\"mean_test_score\", \"params\", \"rank_test_score\", \"std_test_score\"]}\n",
    "    save_json({\"best_score\": float(rs.best_score_), \"best_params\": rs.best_params_}, f\"{name}_best_params.json\")\n",
    "\n",
    "save_json(cv_results_summary, \"cv_results_summary.json\")\n",
    "\n",
    "# ---------------------------\n",
    "# Refit chosen estimators on full training set\n",
    "# ---------------------------\n",
    "print(\"\\nRefitting chosen estimators on full training data...\")\n",
    "for name, est in best_estimators.items():\n",
    "    print(f\"Refitting {name} ...\")\n",
    "    if USE_IMBLEARN:\n",
    "        est.fit(X_train, y_train)\n",
    "    else:\n",
    "        est.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Build stacking classifier (use cloned fitted base estimators)\n",
    "estimators_for_stack = [(name, clone(est)) for name, est in best_estimators.items()]\n",
    "final_estimator = LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "stack_clf = StackingClassifier(estimators=estimators_for_stack, final_estimator=final_estimator, n_jobs=N_JOBS, passthrough=False, verbose=0)\n",
    "\n",
    "# Fit stacking on full balanced data (sampler included inside pipelines if USE_IMBLEARN)\n",
    "if USE_IMBLEARN:\n",
    "    stack_clf.fit(X_train, y_train)\n",
    "else:\n",
    "    stack_clf.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(stack_clf, Path(OUT_DIR) / \"stacking_model_improved.joblib\")\n",
    "for name, est in best_estimators.items():\n",
    "    joblib.dump(est, Path(OUT_DIR) / f\"{name}_best_improved.joblib\")\n",
    "print(\"Saved models.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Evaluate on test set\n",
    "# ---------------------------\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "y_proba = stack_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "metrics_default = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred_default),\n",
    "    \"precision\": precision_score(y_test, y_pred_default, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, y_pred_default, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, y_pred_default, zero_division=0),\n",
    "    \"roc_auc\": float(auc(*roc_curve(y_test, y_proba)[:2])),\n",
    "    \"average_precision\": float(average_precision_score(y_test, y_proba)),\n",
    "    \"confusion_matrix\": confusion_matrix(y_test, y_pred_default).tolist()\n",
    "}\n",
    "metrics_default[\"classification_report\"] = classification_report(y_test, y_pred_default, output_dict=True, zero_division=0)\n",
    "save_json(metrics_default, \"test_metrics_default_threshold.json\")\n",
    "print(\"Default-threshold metrics saved.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Efficient threshold selection using precision_recall_curve\n",
    "# ---------------------------\n",
    "prec_vals, rec_vals, pr_thresholds = precision_recall_curve(y_test, y_proba)\n",
    "# align arrays: prec_vals[:-1], rec_vals[:-1] correspond to pr_thresholds\n",
    "eps = 1e-12\n",
    "p = prec_vals[:-1]\n",
    "r = rec_vals[:-1]\n",
    "f1s = 2 * p * r / (p + r + eps)\n",
    "\n",
    "best_idx = int(np.nanargmax(f1s))\n",
    "best_thresh = float(pr_thresholds[best_idx])\n",
    "best_f1 = float(f1s[best_idx])\n",
    "best_prec = float(p[best_idx])\n",
    "best_rec = float(r[best_idx])\n",
    "\n",
    "save_json({\n",
    "    \"best_threshold_by_f1\": best_thresh,\n",
    "    \"best_f1\": best_f1,\n",
    "    \"precision_at_best\": best_prec,\n",
    "    \"recall_at_best\": best_rec,\n",
    "    \"n_pr_thresholds\": int(len(pr_thresholds))\n",
    "}, \"best_threshold_summary.json\")\n",
    "print(f\"Selected best threshold by PR-F1: {best_thresh:.4f} (F1={best_f1:.4f}, P={best_prec:.4f}, R={best_rec:.4f})\")\n",
    "\n",
    "# Evaluate with chosen threshold\n",
    "y_pred_best = (y_proba >= best_thresh).astype(int)\n",
    "metrics_best = {\n",
    "    \"threshold\": best_thresh,\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred_best),\n",
    "    \"precision\": precision_score(y_test, y_pred_best, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, y_pred_best, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, y_pred_best, zero_division=0),\n",
    "    \"roc_auc\": float(auc(*roc_curve(y_test, y_proba)[:2])),\n",
    "    \"average_precision\": float(average_precision_score(y_test, y_proba)),\n",
    "    \"confusion_matrix\": confusion_matrix(y_test, y_pred_best).tolist()\n",
    "}\n",
    "metrics_best[\"classification_report\"] = classification_report(y_test, y_pred_best, output_dict=True, zero_division=0)\n",
    "save_json(metrics_best, \"test_metrics_best_threshold.json\")\n",
    "print(\"Best-threshold metrics saved.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Plots: ROC, PR (with best point), Confusion matrix (best threshold), Calibration\n",
    "# ---------------------------\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig = plt.figure()\n",
    "plt.plot(fpr, tpr, lw=2, label=f'Stacking (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Apnea=1)'); plt.legend(loc='lower right')\n",
    "save_fig(fig, \"roc_curve_improved.png\")\n",
    "\n",
    "# Precision-Recall (plot and mark best)\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "fig = plt.figure()\n",
    "plt.plot(rec_vals, prec_vals, lw=2, label=f'Stacking (AP={ap:.4f})')\n",
    "plt.scatter([best_rec], [best_prec], color='red', label=f'Best F1 thr={best_thresh:.3f}')\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (Apnea=1)'); plt.legend(loc='lower left')\n",
    "save_fig(fig, \"precision_recall_curve_improved.png\")\n",
    "\n",
    "# Confusion matrix for best threshold\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues')\n",
    "ax.set_xlabel('Predicted'); ax.set_ylabel('Actual')\n",
    "ax.set_title(f'Confusion Matrix (threshold={best_thresh:.3f})')\n",
    "save_fig(fig, \"confusion_matrix_improved.png\")\n",
    "\n",
    "# Calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10)\n",
    "fig = plt.figure()\n",
    "plt.plot(prob_pred, prob_true, marker='o', linewidth=1, label='Stacking')\n",
    "plt.plot([0,1],[0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('Mean predicted probability'); plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration Curve (Apnea=1)'); plt.legend()\n",
    "save_fig(fig, \"calibration_curve_improved.png\")\n",
    "\n",
    "# ---------------------------\n",
    "# Feature importances from tree-based models (if available)\n",
    "# ---------------------------\n",
    "feature_names = list(X_train.columns.astype(str))\n",
    "fi_summary = {}\n",
    "for name, est in best_estimators.items():\n",
    "    try:\n",
    "        clf = None\n",
    "        if hasattr(est, 'named_steps'):\n",
    "            if 'clf' in est.named_steps:\n",
    "                clf = est.named_steps['clf']\n",
    "            else:\n",
    "                clf = list(est.named_steps.values())[-1]\n",
    "        else:\n",
    "            clf = est\n",
    "        if hasattr(clf, \"feature_importances_\"):\n",
    "            importances = clf.feature_importances_\n",
    "            idx = np.argsort(importances)[::-1]\n",
    "            topk = min(20, len(importances))\n",
    "            top_features = [{\"feature\": feature_names[i], \"importance\": float(importances[i])} for i in idx[:topk]]\n",
    "            fi_summary[name] = top_features\n",
    "            fig, ax = plt.subplots(figsize=(8, max(3, topk * 0.3)))\n",
    "            sns.barplot(x=[f[\"importance\"] for f in top_features], y=[f[\"feature\"] for f in top_features], ax=ax)\n",
    "            ax.set_title(f\"Top {topk} feature importances: {name}\")\n",
    "            save_fig(fig, f\"{name}_feature_importances_improved.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"No feature importances for {name} or failed: {e}\")\n",
    "\n",
    "if fi_summary:\n",
    "    save_json(fi_summary, \"feature_importances_improved.json\")\n",
    "\n",
    "# Save predictions\n",
    "pred_df = pd.DataFrame({\"true\": y_test, \"pred_default\": y_pred_default, \"pred_best\": y_pred_best, \"proba\": y_proba})\n",
    "pred_df.to_csv(Path(OUT_DIR) / \"test_predictions_improved.csv\", index=False)\n",
    "print(f\"Saved predictions to {Path(OUT_DIR) / 'test_predictions_improved.csv'}\")\n",
    "\n",
    "# Final summary\n",
    "final_summary = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"default_threshold_metrics\": metrics_default,\n",
    "    \"best_threshold_metrics\": metrics_best,\n",
    "    \"best_threshold\": best_thresh,\n",
    "    \"cv_results_summary\": cv_results_summary,\n",
    "    \"used_imblearn\": USE_IMBLEARN\n",
    "}\n",
    "save_json(final_summary, \"final_summary_improved.json\")\n",
    "\n",
    "print(\"\\nDone. All outputs are in:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58084d70-2537-4220-ad88-380a3a281e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv1",
   "language": "python",
   "name": "tfenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
