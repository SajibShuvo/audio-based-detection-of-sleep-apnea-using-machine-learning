{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22f601c-6192-432f-bd3e-aa235d458bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import csv\n",
    "from scipy.signal import resample_poly\n",
    "\n",
    "\n",
    "def overall_avg_area_moment_cq_mfcc(y,\n",
    "                                    sr=16000,\n",
    "                                    n_mfcc=13,\n",
    "                                    n_bins=84,            # CQT bins (e.g., 7 octaves * 12)\n",
    "                                    bins_per_octave=12,\n",
    "                                    hop_length=512,\n",
    "                                    use_abs_weights=True):\n",
    "    \"\"\"\n",
    "    Compute overall average of area-method (2nd central) moments of constant-Q based MFCCs.\n",
    "    Returns a single float.\n",
    "    \"\"\"\n",
    "    # 1) load audio (mono)\n",
    "    # y, _ = librosa.load(path, sr=sr, mono=True, duration=None)\n",
    "\n",
    "    # 2) compute CQT magnitude (power)\n",
    "    C = librosa.cqt(y, sr=sr, hop_length=hop_length,\n",
    "                    n_bins=n_bins, bins_per_octave=bins_per_octave)\n",
    "    # C is complex; convert to power\n",
    "    C_power = np.abs(C)**2\n",
    "\n",
    "    # 3) convert to log-power (dB)\n",
    "    C_db = librosa.power_to_db(C_power, ref=np.max)\n",
    "\n",
    "    # 4) compute MFCCs from this log-CQT spectrogram\n",
    "    # librosa.feature.mfcc expects either y or S (Mel spectrogram), but giving S works:\n",
    "    # pass S as log-power (linear scale expected) â€” we supply C_db which is in dB, so convert back:\n",
    "    # librosa.feature.mfcc expects \"S\" in power (not dB), so we'll convert dB back to amplitude-like:\n",
    "    S_for_mfcc = librosa.db_to_power(C_db)\n",
    "    mfccs = librosa.feature.mfcc(S=S_for_mfcc, n_mfcc=n_mfcc)\n",
    "\n",
    "    # mfccs shape: (n_mfcc, n_frames)\n",
    "    n_m, n_t = mfccs.shape\n",
    "    moments = np.zeros(n_m)\n",
    "\n",
    "    # frame indices (use numeric frame positions as 'distance' axis)\n",
    "    t_idx = np.arange(n_t, dtype=np.float64)\n",
    "\n",
    "    for m in range(n_m):\n",
    "        coeff = mfccs[m, :]\n",
    "\n",
    "        # weight = absolute value or squared depending on preference\n",
    "        if use_abs_weights:\n",
    "            w = np.abs(coeff)\n",
    "        else:\n",
    "            w = coeff**2\n",
    "\n",
    "        # avoid zero total weight\n",
    "        W = w.sum()\n",
    "        if W <= 0:\n",
    "            moments[m] = 0.0\n",
    "            continue\n",
    "\n",
    "        centroid = (t_idx * w).sum() / W\n",
    "        second_central = (( (t_idx - centroid)**2 ) * w).sum() / W\n",
    "        moments[m] = second_central\n",
    "\n",
    "    # overall average of the per-band area moments\n",
    "    overall_avg = float(moments.mean())\n",
    "    return overall_avg\n",
    "\n",
    "# Example usage:\n",
    "# result = overall_avg_area_moment_cq_mfcc(\"path/to/your_9s_clip.wav\")\n",
    "# print(\"Overall average area moment (constant-Q MFCCs):\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00447c09-7dc7-4725-a079-e0d6d6b1dcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening (memmap) /scratch/sshuvo13/project_shared_folder_bspml_1/segmented_edfs/female_segmented_edfs/00000995-100507_segmented.npy\n",
      "Finished 00000995-100507_segmented.npy, wrote /scratch/sshuvo13/project_shared_folder_bspml_1/whole_dataset_features/female/Q_MFCC_avg/00000995-100507_frac_low_en_features.csv\n"
     ]
    }
   ],
   "source": [
    "def main(patient_id, data_dir, label_dir, output_dir):\n",
    "\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    filename = f\"{patient_id}_segmented.npy\"\n",
    "    segments_file_path = os.path.join(data_dir, filename)\n",
    "    print(f\"Opening (memmap) {segments_file_path}\")\n",
    "    segments = np.load(segments_file_path, mmap_mode='r')  # <-- memory-mapped\n",
    "\n",
    "    if segments.ndim != 2:\n",
    "        print(f\"File {filename} does not contain a 2D array; skipping.\")\n",
    "        return\n",
    "\n",
    "    # load labels (still likely small)\n",
    "    label_file_name = f\"{patient_id}_segments_labels.npy\"\n",
    "    label_file_path = os.path.join(label_dir, label_file_name)\n",
    "    label_file = np.load(label_file_path)  # if this is huge, memmap it too\n",
    "\n",
    "    number_of_segments = segments.shape[0]\n",
    "    labels_subset = label_file[:number_of_segments]\n",
    "\n",
    "    # Prepare CSV output (write header)\n",
    "    output_file = os.path.join(output_dir, f\"{patient_id}_Q_MFCC_avg.csv\")\n",
    "    header_written = False\n",
    "\n",
    "    # iterate by index to avoid copying the whole 'segments' at once\n",
    "    for i in range(number_of_segments):\n",
    "        try:\n",
    "            seg = segments[i]            # this is a memmap slice (view)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading segment {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # resample to 16k\n",
    "        try:\n",
    "            signal_16khz = resample_to_16k(seg, orig_sr=48000, target_sr=16000)\n",
    "        except Exception:\n",
    "            # fallback to librosa if needed\n",
    "            signal_16khz = librosa.resample(np.asarray(seg, dtype=np.float32), orig_sr=48000, target_sr=16000)\n",
    "\n",
    "\n",
    "        #custom feature function goes here\n",
    "        feats_raw = overall_avg_area_moment_cq_mfcc(signal_16khz)\n",
    "        feats = {'Q_MFCC_avg': feats_raw}\n",
    "        feats['label'] = labels_subset[i] if i < len(labels_subset) else None\n",
    "        feats['segment_index'] = i\n",
    "\n",
    "        # write row immediately to CSV (append)\n",
    "        if not header_written:\n",
    "            with open(output_file, 'w', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=list(feats.keys()))\n",
    "                writer.writeheader()\n",
    "                writer.writerow(feats)\n",
    "            header_written = True\n",
    "        else:\n",
    "            with open(output_file, 'a', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=list(feats.keys()))\n",
    "                writer.writerow(feats)\n",
    "\n",
    "    print(f\"Finished {filename}, wrote {output_file}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read environment variables set by job.sh\n",
    "    # patient_id = os.environ.get(\"PATIENT_ID\")\n",
    "    # data_dir = os.environ.get(\"DATA_DIR\")\n",
    "    # label_dir = os.environ.get(\"LABEL_DIR\")\n",
    "    # output_dir = os.environ.get(\"OUTPUT_DIR\")\n",
    "\n",
    "\n",
    "\n",
    "    # Simple check\n",
    "    if not all([patient_id, data_dir, label_dir, output_dir]):\n",
    "        raise ValueError(\"Missing required environment variables: PATIENT_ID, DATA_DIR, LABEL_DIR, OUTPUT_DIR\")\n",
    "\n",
    "    # print(f\"\\nProcessing patient: {patient_id}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    main(patient_id, data_dir, label_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310d377-230c-4480-9122-f555de97df5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv1",
   "language": "python",
   "name": "tfenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
