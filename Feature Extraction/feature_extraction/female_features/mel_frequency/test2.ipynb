{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff5c203-ced9-48fb-9d80-3cd4245068ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 3524/3524 [00:35<00:00, 100.36seg/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from typing import Optional, Sequence, Union\n",
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "# fs = 48000  # Hz\n",
    "\n",
    "\n",
    "# def find_file_with_prefix(directory, prefix, extension):\n",
    "#     \"\"\"\n",
    "#     Search 'directory' for a file starting with 'prefix' and ending with 'extension'.\n",
    "#     Returns the full path if found; raises an error otherwise.\n",
    "#     \"\"\"\n",
    "#     for name in os.listdir(directory):\n",
    "#         if name.startswith(prefix) and name.endswith(extension):\n",
    "#             return os.path.join(directory, name)\n",
    "#     raise FileNotFoundError(f\"No file found for ID {prefix} with {extension} in {directory}\")\n",
    "\n",
    "# ********************** Paste your whole function here **********************\n",
    "\n",
    "target_sample_rate = 16000\n",
    "original_sample_rate = 48000\n",
    "\n",
    "def process_segment(\n",
    "    x: np.ndarray,\n",
    "    sr_target: int = 16000,\n",
    "    orig_sr: Optional[int] = None,\n",
    "    n_fft: int = 512,\n",
    "    win_length: int = 400,\n",
    "    hop_length: int = 160,\n",
    "    n_mels: int = 64,\n",
    "    add_deltas: bool = True,\n",
    "    target_dur: float = 9.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Process a single 1D audio segment -> feature tensor (C, n_mels, frames).\n",
    "    If orig_sr is None, assumes x is already at sr_target.\n",
    "    \"\"\"\n",
    "    # ensure float32\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "\n",
    "    # resample if user provided an orig_sr and it's different\n",
    "    if orig_sr is not None and orig_sr != sr_target:\n",
    "        x = librosa.resample(x, orig_sr=orig_sr, target_sr=sr_target)\n",
    "\n",
    "    # trim/pad to target duration\n",
    "    target_len = int(target_dur * sr_target)\n",
    "    if x.shape[0] < target_len:\n",
    "        x = np.pad(x, (0, target_len - x.shape[0]))\n",
    "    else:\n",
    "        x = x[:target_len]\n",
    "\n",
    "    # mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=x,\n",
    "        sr=sr_target,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    # convert to dB (log)\n",
    "    logmel = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # per-band CMVN (per-segment)\n",
    "    mean = logmel.mean(axis=1, keepdims=True)\n",
    "    std = logmel.std(axis=1, keepdims=True) + 1e-9\n",
    "    logmel_norm = (logmel - mean) / std\n",
    "\n",
    "    if add_deltas:\n",
    "        delta = librosa.feature.delta(logmel_norm)\n",
    "        delta2 = librosa.feature.delta(logmel_norm, order=2)\n",
    "        features = np.stack([logmel_norm, delta, delta2], axis=0)  # (3, n_mels, frames)\n",
    "    else:\n",
    "        features = logmel_norm[np.newaxis, :, :]  # (1, n_mels, frames)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_batch_from_npy(\n",
    "    npy_path: str,\n",
    "    sr_target: int = 16000,\n",
    "    orig_sr: Optional[Union[int, Sequence[int]]] = None,\n",
    "    n_fft: int = 512,\n",
    "    win_length: int = 400,\n",
    "    hop_length: int = 160,\n",
    "    n_mels: int = 64,\n",
    "    add_deltas: bool = True,\n",
    "    target_dur: float = 9.0,\n",
    "    show_progress: bool = True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load a .npy file that contains a list/array of segments and extract features for all.\n",
    "    Returns: np.ndarray of shape (N, C, n_mels, frames)\n",
    "\n",
    "    Parameters:\n",
    "    - orig_sr: either\n",
    "        - None (assume all segments already at sr_target), or\n",
    "        - single int (all segments share the same original sr), or\n",
    "        - sequence of ints with length == N (original sr per segment).\n",
    "    \"\"\"\n",
    "    container = np.load(npy_path, allow_pickle=True)\n",
    "    # container may be an array of arrays or list\n",
    "    segments = list(container)\n",
    "\n",
    "    N = len(segments)\n",
    "    # process a single dummy to determine frames and C\n",
    "    example_features = process_segment(\n",
    "        segments[0],\n",
    "        sr_target=sr_target,\n",
    "        orig_sr=(orig_sr[0] if (isinstance(orig_sr, (list, tuple, np.ndarray)) and len(orig_sr) > 0) else orig_sr),\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_length,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        add_deltas=add_deltas,\n",
    "        target_dur=target_dur\n",
    "    )\n",
    "    C, H, W = example_features.shape\n",
    "\n",
    "    # allocate output array\n",
    "    out = np.zeros((N, C, H, W), dtype=np.float32)\n",
    "\n",
    "    iterator = range(N)\n",
    "    if show_progress:\n",
    "        iterator = tqdm.tqdm(iterator, desc=\"Extracting features\", unit=\"seg\")\n",
    "\n",
    "    for i in iterator:\n",
    "        seg = segments[i]\n",
    "        this_orig_sr = None\n",
    "        if isinstance(orig_sr, (list, tuple, np.ndarray)):\n",
    "            this_orig_sr = orig_sr[i]\n",
    "        elif isinstance(orig_sr, int):\n",
    "            this_orig_sr = orig_sr\n",
    "        # process\n",
    "        feats = process_segment(\n",
    "            seg,\n",
    "            sr_target=sr_target,\n",
    "            orig_sr=this_orig_sr,\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            hop_length=hop_length,\n",
    "            n_mels=n_mels,\n",
    "            add_deltas=add_deltas,\n",
    "            target_dur=target_dur\n",
    "        )\n",
    "        # safety: if frames differ, trim/pad along time axis\n",
    "        if feats.shape[2] != W:\n",
    "            # if shorter -> pad, if longer -> trim\n",
    "            if feats.shape[2] < W:\n",
    "                pad_width = W - feats.shape[2]\n",
    "                feats = np.pad(feats, ((0,0),(0,0),(0,pad_width)))\n",
    "            else:\n",
    "                feats = feats[:, :, :W]\n",
    "        out[i] = feats\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "\n",
    "# def process_patient(patient_id, data, labels):\n",
    "#     \"\"\"\n",
    "#     Compute features for a patient.\n",
    "#     \"\"\"\n",
    "   \n",
    "#     if data.ndim > 1:\n",
    "#         signal = data[0]\n",
    "#     else:\n",
    "#         signal = data\n",
    "#     # ********* Use your function here *************************\n",
    "#     # feature = your_function_here(signal, fs)\n",
    "#     f0 = fundamental_frequency_fft(signal, fs, fmin=1, fmax=5000)\n",
    "#     # ***********************************************************\n",
    "#     return {\n",
    "#         \"patient_id\": patient_id,\n",
    "#         # \"feature\": feature # <-- **** Output of your function *****\n",
    "#         \"fundamental_frequency\": f0 # <-- **** Output of your function ***** \n",
    "#     }\n",
    "\n",
    "\n",
    "def main(patient_id, data_dir, label_dir, output_dir):\n",
    "    segment_file_paths = []\n",
    "    segment_file_names = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.npy'):\n",
    "            segment_file_paths.append(os.path.join(data_dir, filename))\n",
    "            segment_file_names.append(filename)\n",
    "\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for segment_file_path in segment_file_paths:\n",
    "        \n",
    "        features_batch = extract_batch_from_npy(\n",
    "        segment_file_path,\n",
    "        sr_target=16000,\n",
    "        orig_sr=48000,         # assume segments already 16kHz; set int or list if different\n",
    "        n_fft=512,\n",
    "        win_length=400,\n",
    "        hop_length=160,\n",
    "        n_mels=64,\n",
    "        add_deltas=True,\n",
    "        target_dur=9.0,\n",
    "        show_progress=True\n",
    "        )\n",
    "        match = re.search(r\"/([0-9]+-[0-9]+)_segmented\\.npy$\", segment_file_path)\n",
    "        file_name = match.group(1)\n",
    "        np.save(os.path.join(output_dir, f\"{file_name}.npy\"), features_batch)\n",
    "        break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read environment variables set by job.sh\n",
    "    # patient_id = os.environ.get(\"PATIENT_ID\")\n",
    "    # data_dir = os.environ.get(\"DATA_DIR\")\n",
    "    # label_dir = os.environ.get(\"LABEL_DIR\")\n",
    "    # output_dir = os.environ.get(\"OUTPUT_DIR\")\n",
    "\n",
    "    patient_id = \"00001006-100507\"\n",
    "    data_dir = \"/scratch/sshuvo13/project_shared_folder_bspml_1/segmented_edfs/male_segmented_edfs\"\n",
    "    label_dir =\"/scratch/sshuvo13/project_shared_folder_bspml_1/rml_analysis/segment_csv_data/segment_details\"\n",
    "    output_dir = \"/scratch/sshuvo13/project_shared_folder_bspml_1/whole_dataset_features/male/mel_spectrum\"\n",
    "\n",
    "    # Simple check\n",
    "    if not all([patient_id, data_dir, label_dir, output_dir]):\n",
    "        raise ValueError(\"Missing required environment variables: PATIENT_ID, DATA_DIR, LABEL_DIR, OUTPUT_DIR\")\n",
    "\n",
    "    # print(f\"\\nProcessing patient: {patient_id}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    main(patient_id, data_dir, label_dir, output_dir)\n",
    "    print(\"Done\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv1",
   "language": "python",
   "name": "tfenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
